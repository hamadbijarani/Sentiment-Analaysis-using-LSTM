{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "93c78b10",
      "metadata": {
        "id": "93c78b10"
      },
      "source": [
        "# Sentiment Analysis using LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the libraries"
      ],
      "metadata": {
        "id": "mbE3WwDvaXvX"
      },
      "id": "mbE3WwDvaXvX"
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gensim\n",
        "\n",
        "# Restart runtime session (shortkey: ctrl+m . ):\n",
        "#       Runtime -> Restart session"
      ],
      "metadata": {
        "id": "iGA-yOAJa3RZ"
      },
      "id": "iGA-yOAJa3RZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "044e5f19",
      "metadata": {
        "id": "044e5f19"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import pickle\n",
        "import kagglehub\n",
        "import tensorflow as tf\n",
        "from gensim.models import KeyedVectors\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from keras.src.layers import Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.src.legacy.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, Lambda, Reshape\n",
        "import sys\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "332c4a51",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "332c4a51",
        "outputId": "4b8e7224-4aea-4e45-c0e9-1a2d6425d6bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import data"
      ],
      "metadata": {
        "id": "bvKzK-qtadZt"
      },
      "id": "bvKzK-qtadZt"
    },
    {
      "cell_type": "code",
      "source": [
        "!#!/bin/bash\n",
        "!curl -L -o sentiment-analysis-dataset.zip\\\n",
        "  https://www.kaggle.com/api/v1/datasets/download/abhi8923shriv/sentiment-analysis-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbYw5qoiZsTL",
        "outputId": "6cab7c01-4bb8-44e8-9405-667d62ae6647"
      },
      "id": "GbYw5qoiZsTL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 54.4M  100 54.4M    0     0  9819k      0  0:00:05  0:00:05 --:--:-- 13.1M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./sentiment-analysis-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmxuoDyWZzE4",
        "outputId": "7e091ad2-fc95-49a2-938f-85e64e7cbb4c"
      },
      "id": "FmxuoDyWZzE4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./sentiment-analysis-dataset.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: testdata.manual.2009.06.14.csv  \n",
            "  inflating: train.csv               \n",
            "  inflating: training.1600000.processed.noemoticon.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1f0857b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1f0857b",
        "outputId": "8314c5b1-db78-4f1f-988b-15bd2d3d648c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27481 entries, 0 to 27480\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   textID            27481 non-null  object \n",
            " 1   text              27480 non-null  object \n",
            " 2   selected_text     27480 non-null  object \n",
            " 3   sentiment         27481 non-null  object \n",
            " 4   Time of Tweet     27481 non-null  object \n",
            " 5   Age of User       27481 non-null  object \n",
            " 6   Country           27481 non-null  object \n",
            " 7   Population -2020  27481 non-null  int64  \n",
            " 8   Land Area (Km²)   27481 non-null  float64\n",
            " 9   Density (P/Km²)   27481 non-null  int64  \n",
            "dtypes: float64(1), int64(2), object(7)\n",
            "memory usage: 2.1+ MB\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv('/content/train.csv', encoding='latin1')\n",
        "test = pd.read_csv('/content/test.csv', encoding='latin1')\n",
        "\n",
        "train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ],
      "metadata": {
        "id": "std7tOjeagV6"
      },
      "id": "std7tOjeagV6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad19d858",
      "metadata": {
        "id": "ad19d858"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return ' '.join(filtered_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "030afc03",
      "metadata": {
        "id": "030afc03"
      },
      "outputs": [],
      "source": [
        "train = train.dropna()\n",
        "\n",
        "X_train = train[['text']]\n",
        "y_train = train['sentiment'].map({'positive': 1, 'negative': -1, 'neutral': 0})\n",
        "\n",
        "test = test.dropna()\n",
        "X_test = test[['text']]\n",
        "y_test = test['sentiment'].map({'positive': 1, 'negative': -1, 'neutral': 0})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(y_test.isna()), y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktc2vLVUsW_-",
        "outputId": "16a3528f-b4e7-440e-c4b7-3a0175d837d6"
      },
      "id": "Ktc2vLVUsW_-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, (3534,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "920364f7",
      "metadata": {
        "id": "920364f7"
      },
      "outputs": [],
      "source": [
        "# Flatten the text data\n",
        "train_texts = X_train['text'].astype(str).apply(remove_stopwords)\n",
        "test_texts = X_test['text'].astype(str).apply(remove_stopwords)\n",
        "\n",
        "y_train = to_categorical(y_train.astype(int).tolist(), num_classes=3)\n",
        "y_test = to_categorical(y_test.astype(int).tolist(), num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce16ba47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce16ba47",
        "outputId": "a3b35d23-160a-4395-8aa9-2d243716c62c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day 1\n",
            "good 2\n",
            "get 3\n",
            "like 4\n",
            "go 5\n"
          ]
        }
      ],
      "source": [
        "# Tokenize\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "train_seq = tokenizer.texts_to_sequences(train_texts)\n",
        "test_seq = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "max_len = max(max(len(seq) for seq in train_seq), 50)\n",
        "\n",
        "X_train_pad = pad_sequences(train_seq, max_len)\n",
        "X_test_pad = pad_sequences(test_seq, max_len)\n",
        "\n",
        "word_idx = tokenizer.word_index\n",
        "\n",
        "# print first 5 keys\n",
        "for key in list(word_idx.keys())[:5]:\n",
        "    print(key, word_idx[key])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e937b94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e937b94",
        "outputId": "08903c4d-ff3a-4755-913b-e3d79a26de57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27480, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X_train_pad.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c761036",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c761036",
        "outputId": "4a5998a3-5824-4e7c-d508-1c572d61eb9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3534, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X_test_pad.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40d5d5b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40d5d5b0",
        "outputId": "2e20fc80-52a7-4943-d546-4bb3fc7d016d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/leadbest/googlenewsvectorsnegative300?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.17G/3.17G [02:35<00:00, 21.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/leadbest/googlenewsvectorsnegative300/versions/2/GoogleNews-vectors-negative300.bin\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"leadbest/googlenewsvectorsnegative300\")\n",
        "path += '/GoogleNews-vectors-negative300.bin'\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "word2vec = KeyedVectors.load_word2vec_format(path, binary=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 300\n",
        "vocab_size = len(word_idx)+1\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, i in word_idx.items():\n",
        "    if word in word2vec:\n",
        "        embedding_matrix[i] = word2vec[word]\n"
      ],
      "metadata": {
        "id": "7KnrufbjcD8i"
      },
      "id": "7KnrufbjcD8i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkEWyptkcPOD",
        "outputId": "202fb2bb-3a70-4d72-9f3f-3840839775c6"
      },
      "id": "zkEWyptkcPOD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23350, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building LSTM Attention Sentiment Classifier"
      ],
      "metadata": {
        "id": "L4D4Z2prc2Kn"
      },
      "id": "L4D4Z2prc2Kn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the attention layer\n",
        "class AttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "        self.u = None\n",
        "        self.b = None\n",
        "        self.W = None\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        \"\"\"Trainable weights for attention mechanism\"\"\"\n",
        "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], input_shape[-1]),\n",
        "                                 initializer=\"glorot_uniform\", trainable=True)\n",
        "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[-1],),\n",
        "                                 initializer=\"zeros\", trainable=True)\n",
        "        self.u = self.add_weight(name=\"att_u\", shape=(input_shape[-1],),\n",
        "                                 initializer=\"glorot_uniform\", trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Score computation\n",
        "        v = tf.tanh(tf.tensordot(inputs, self.W, axes=1) + self.b)\n",
        "        vu = tf.tensordot(v, self.u, axes=1)\n",
        "\n",
        "        alphas = tf.nn.softmax(vu)\n",
        "\n",
        "        # weighted sum of input\n",
        "        output = tf.reduce_sum(inputs * tf.expand_dims(alphas, -1), axis=1)\n",
        "        return output, alphas"
      ],
      "metadata": {
        "id": "Hqsqfd0FcQsA"
      },
      "id": "Hqsqfd0FcQsA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Bi-LSTM model with Attention\n",
        "def create_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    embedding_layer = Embedding(\n",
        "        input_dim = vocab_size,\n",
        "        output_dim = embedding_dim,\n",
        "        input_length = max_len,\n",
        "        trainable=True)(inputs)\n",
        "\n",
        "    #Bi LSTM layer\n",
        "    lstm_out = Bidirectional(LSTM(64, return_sequences=True))(embedding_layer)\n",
        "\n",
        "    # Add Attention Layer\n",
        "    attention_out, attention_weights = AttentionLayer()(lstm_out)\n",
        "\n",
        "    reshaped = Reshape((1, 128))(attention_out)\n",
        "\n",
        "    # LSTM layer post attention\n",
        "    lstm_after_attn = LSTM(64, return_sequences=False)(reshaped)\n",
        "\n",
        "    # Flatten Layer\n",
        "    dense = Dense(128, activation='relu')(lstm_after_attn)\n",
        "\n",
        "    # Final Dense Layer\n",
        "    outputs = Dense(3, activation='softmax')(lstm_after_attn)\n",
        "\n",
        "    # Define the model\n",
        "    return Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "G9kFc9pLdxzl"
      },
      "id": "G9kFc9pLdxzl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set input shapes and compile the model\n",
        "input_shape = (50,)\n",
        "\n",
        "model = create_model(input_shape)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "11__WteKkN7F",
        "outputId": "1689e73d-a015-4e4b-ceb8-1e74e2e87cb1"
      },
      "id": "11__WteKkN7F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m300\u001b[0m)        │     \u001b[38;5;34m7,005,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m186,880\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_layer                 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │        \u001b[38;5;34m16,640\u001b[0m │\n",
              "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │ \u001b[38;5;34m50\u001b[0m)]                   │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,005,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">186,880</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ attention_layer                 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │ <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)]                   │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,258,123\u001b[0m (27.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,258,123</span> (27.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,258,123\u001b[0m (27.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,258,123</span> (27.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "model.fit(X_train_pad, np.array(y_train), epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq-U87UykjUp",
        "outputId": "99610fab-5aa3-4523-ee13-817cff7bd401"
      },
      "id": "uq-U87UykjUp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 16ms/step - accuracy: 0.5422 - loss: 0.9130 - val_accuracy: 0.7249 - val_loss: 0.6790\n",
            "Epoch 2/10\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - accuracy: 0.8005 - loss: 0.5058 - val_accuracy: 0.7118 - val_loss: 0.7118\n",
            "Epoch 3/10\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.8879 - loss: 0.3184 - val_accuracy: 0.7043 - val_loss: 0.8160\n",
            "Epoch 4/10\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9305 - loss: 0.2087 - val_accuracy: 0.6830 - val_loss: 1.0028\n",
            "Epoch 5/10\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9548 - loss: 0.1357 - val_accuracy: 0.6727 - val_loss: 1.1349\n",
            "Epoch 6/10\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.9682 - loss: 0.0976 - val_accuracy: 0.6585 - val_loss: 1.3991\n",
            "Epoch 7/10\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9719 - loss: 0.0807 - val_accuracy: 0.6650 - val_loss: 1.5285\n",
            "Epoch 8/10\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - accuracy: 0.9781 - loss: 0.0623 - val_accuracy: 0.6512 - val_loss: 1.7401\n",
            "Epoch 9/10\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.9813 - loss: 0.0540 - val_accuracy: 0.6503 - val_loss: 2.0194\n",
            "Epoch 10/10\n",
            "\u001b[1m687/687\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9831 - loss: 0.0476 - val_accuracy: 0.6576 - val_loss: 1.9830\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f1a3f4ea890>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model on test dataset"
      ],
      "metadata": {
        "id": "JSWYevTuRveb"
      },
      "id": "JSWYevTuRveb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Model\n",
        "loss, accuracy = model.evaluate(X_test_pad, np.array(y_test))\n"
      ],
      "metadata": {
        "id": "TwTLTIOIlIjT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1992c84f-546b-4adc-a277-a7e5412a72f8"
      },
      "id": "TwTLTIOIlIjT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6496 - loss: 1.9803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "E_Ing08-qWIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b826853c-77c9-4ea0-84a5-3617b7e789df"
      },
      "id": "E_Ing08-qWIj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 64.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the model is trained on train_set, we can see that it acheives an accuracy of 59.47% which is pretty good given dataset size, and simplicity of the network. Given more data, it is possible that this network would perform better."
      ],
      "metadata": {
        "id": "aBDFYkHiqfay"
      },
      "id": "aBDFYkHiqfay"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the trained model"
      ],
      "metadata": {
        "id": "0fgAQV46P_oh"
      },
      "id": "0fgAQV46P_oh"
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text: str):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return ' '.join(filtered_tokens)"
      ],
      "metadata": {
        "id": "wJ7HmJiAR6vY"
      },
      "id": "wJ7HmJiAR6vY",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text: str):\n",
        "    cleaned = preprocess_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([cleaned])\n",
        "    padded = pad_sequences(seq, maxlen=max_len)\n",
        "    pred = model.predict(padded)[0]\n",
        "    label_map = {0: 'neutral', 1: 'positive', 2: 'negative'}\n",
        "    predicted_class = np.argmax(pred)\n",
        "    return label_map[predicted_class], float(pred[predicted_class])"
      ],
      "metadata": {
        "id": "1wWi33gEP_Kh"
      },
      "id": "1wWi33gEP_Kh",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment, conf = predict_sentiment(\"It is an excellent movie. Would love to watch again!\")\n",
        "print(f\"Sentiment: {sentiment} (Confidence: {conf})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DJy-ocHQHxD",
        "outputId": "4c8787bf-c4fb-40ac-bee7-c4a7973ffc2e"
      },
      "id": "8DJy-ocHQHxD",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Sentiment: positive (Confidence: 0.9999539852142334)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment, conf = predict_sentiment(\"The novel is really lengthy and slow. Storyline is so uninteresting and terrible.\")\n",
        "print(f\"Sentiment: {sentiment} (Confidence: {conf})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI9V7sMrfF3_",
        "outputId": "48afecc9-ddca-4bf9-cccb-fe984e2df198"
      },
      "id": "BI9V7sMrfF3_",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Sentiment: negative (Confidence: 0.9986549615859985)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model for future use"
      ],
      "metadata": {
        "id": "Uxmp7lUfrNAW"
      },
      "id": "Uxmp7lUfrNAW"
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"sentiment_model.keras\")"
      ],
      "metadata": {
        "id": "qlKQ3Pq36_LJ"
      },
      "id": "qlKQ3Pq36_LJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"preprocessing.pkl\", \"wb\") as f:\n",
        "    pickle.dump({\n",
        "        \"tokenizer\": tokenizer,\n",
        "        \"max_len\": max_len,\n",
        "        \"stop_words\": stop_words\n",
        "    }, f)"
      ],
      "metadata": {
        "id": "r26H6ZdQCV9T"
      },
      "id": "r26H6ZdQCV9T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D7tnntjSVVh3"
      },
      "id": "D7tnntjSVVh3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}